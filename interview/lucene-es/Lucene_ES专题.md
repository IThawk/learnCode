## 技能

### 1、倒排索引深入骨髓

- #### 倒排索引的原理以及它是用来解决哪些问题（谈谈你对倒排索引的理解）
```
倒排索引记录每个词条出现在哪些文档，及在文档中的位置，可以根据词条快速定位到包含这个词条的文档及出现的位置。
```

- #### 倒排索引底层数据结构（倒排索引的数据结构）
```
  Term（单词）：一段文本经过分析器分析以后就会输出一串单词，这一个一个的就叫做Term（直译为：单词）

  Term Dictionary（单词字典）：顾名思义，它里面维护的是Term，可以理解为Term的集合

  Term Index（单词索引）：为了更快的找到某个单词，我们为单词建立索引

  Posting List（倒排列表）：倒排列表记录了出现过某个单词的所有文档的文档列表及单词在该文档中出现的位置信息，每条记录称为一个倒排项(Posting)。根据倒排列表，即可获知哪些文档包含某个单词。
  
  创建倒排索引，分为以下几步：
  1）创建文档列表：
  lucene首先对原始文档数据进行编号（DocID），形成列表，就是一个文档列表
  2）创建倒排索引列表
  对文档中数据进行分词，得到词条（分词后的一个又一个词）。对词条进行编号，以词条创建索引。然后记录下包含该词条的所有文档编号（及其它信息）。

  搜索的过程：
  1）当用户输入任意的词条时，首先对用户输入的数据进行分词，得到用户要搜索的所有词条，
  2）然后拿着这些词条去倒排索引列表中进行匹配。找到这些词条就能找到包含这些词条的所有文档的编号。
  3）然后根据这些编号去文档列表中找到文档

索引(Index)：
  在Lucene中一个索引是放在一个文件夹中的。
如下图，同一文件夹中的所有的文件构成一个Lucene索引。
段(Segment)：
按层次保存了从索引，一直到词的包含关系：索引(Index) –> 段(segment) –> 文档(Document) –> 域(Field) –> 词(Term)
也即此索引包含了那些段，每个段包含了那些文档，每个文档包含了那些域，每个域包含了那些词。
一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并。
如上图，具有相同前缀文件的属同一个段，图中共一个段 "_0" 。
segments.gen和segments_1是段的元数据文件，也即它们保存了段的属性信息。
```

- #### 倒排表的压缩算法（底层算法）

  ![FOR和RBM压缩算法](.\images\倒排索引\FOR和RBM压缩算法.jpg)
```

一元编码和二进制编码

这个是所有倒排列表压缩算法的基础构成元素

1:Elias Gamma算法和Elias Delta算法

Elias Gamma压缩算法利用分解函数将待压缩的数字分解为两个因子，之后分别用一元编码和二进制编码来表示这两个因子（刚才都说了嘛，一元编码和二进制编码是这些算法的基础构件）。

该算法的分解函数：X = 2e + d

2:Golomb算法和Rice算法

Golomb算法和Rice算法大致思路和上述两个Elias算法类似，即根据分解函数将待压缩数字分解为两个因子，分别用一元编码和二进制编码表示即可，不同之处在于采取了不一样的分解函数

对于Golomb 和 Rice 算法来说：因子1 = （X-1）/b    因子2 = （X-1）mod b

然后将因子1这个数值加上1之后采用一元编码压缩，因子2使用比特宽度为log(b)的二进制编码。


3:PForDelta算法

PForDelta压缩算法是目前解压缩速度最快的一种倒排文件压缩算法。

该算法基本出发点就是尽可能一次性压缩和解压多个数值。
```
- #### Trie字典树（Prefix Trees）原理（类似题目：B-Trees/B+Trees/红黑树等）
```
Trie字典树基本性质

1，根节点不包含字符，除根节点意外每个节点只包含一个字符。

2，从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。

3，每个节点的所有子节点包含的字符串不相同。

```

- #### FST原理（FST的构建过程以及FST在Lucene中的应用原理）

  ![Trie以及FST原理](.\images\倒排索引\Trie以及FST原理.jpg)
```
  lucene从4开始大量使用的数据结构是FST（Finite State Transducer）。FST有两个优点：1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；2）查询速度快。O(len(str))的查询时间复杂度。

```

- #### 索引文件的内部结构（.tip和.tim文件内部数据结构）

  ![tip和tim的文件内部结构](.\images\倒排索引\tip和tim的文件内部结构.jpg)

- #### FST在Lucene的读写过程（Lucene源码实现）

  ![FST在Lucene的构建过程](.\images\倒排索引\FST在Lucene的构建过程.jpg)

![FST在Lucene的实现原理](.\images\倒排索引\FST在Lucene的实现原理.jpg)
### 2、ES基本操作
```
GET _search
{
  "query": {
    "match_all": {}
  }
}

#删除索引
DELETE pms

GET pms

#查询索引的所有的term
GET /pms/_mapping

#创建索引以及mapping
PUT /test
{
  "settings": {},
  "mappings": {
      "properties": {
        "title": {
          "type": "text",
          "analyzer": "ik_max_word"
        }
      }
  }
}

GET test

#添加文档自动生成ID
POST /test/_doc/
{
  "title": "小米手机",
  "images": "http://image.lagou.com/12479122.jpg",
  "price": 2699
}

GET /test/_search

#根据ID查询数据
GET /test/_doc/nL2Jjn0BuIwF7f74YRgg

#添加文档指定ID
POST /test/_doc/2
{
  "title": "大米手机",
  "images": "http://image.lagou.com/12479122.jpg",
  "price": 2899
}

POST /test/_doc/3
{
  "title": "大米电视",
  "images": "http://image.lagou.com/12479122.jpg",
  "price": 2899
}

POST /test/_doc/4
{
  "title": "小米电视",
  "images": "http://image.lagou.com/12479122.jpg",
  "price": 2899
}

POST /test/_doc/5
{
  "title": "大米手机",
  "images": "http://image.lagou.com/12479122.jpg",
  "price": 2899
}


GET /test/_doc/2

#修改数据
PUT /test/_doc/2
{
  "title": "超米手机",
  "images": "http://image.lagou.com/12479122.jpg",
  "price": 3899,
  "stock": 100,
  "saleable": true
}

#查询所有
GET /test/_search
{
  "query": {
    "match_all": {}
  }
}


# 条件查询 or
GET /test/_search
{
  "query": {
    "match": {
      "title": "小米电视"
    }
  }
}

# 条件查询 and
GET /test/_search
{
  "query": {
    "match": {
      "title": {
        "query": "小米电视",
        "operator": "and"
      }
    }
  }
}
#term 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些未分词的字符串,keyword类型的字符串
GET /test/_search
{
  "query": {
    "term": {
      "price": 2699
    }
  }
}

# bool 查询 bool 把各种其它查询通过must （与）、must_not （非）、should （或）的方式进行组合
GET /test/_search
{
  "query": {
    "bool": {
      "must": {
        "match": {
          "title": "大米"
        }
      },
      "must_not": {
        "match": {
          "title": "电视"
        }
      },
      "should": {
        "match": {
          "title": "手机"
        }
      }
    }
  }
}

POST /test/_doc/5
{
  "title": "apple手机",
  "images": "http://image.lagou.com/12479122.jpg",
  "price": 6899
}


#range 查询找出那些落在指定区间内的数字或者时间
GET /test/_search
{
  "query": {
    "range": {
      "price": {
        "gte": 1000,
        "lt": 2800
      }
    }
  }
}

#fuzzy 查询是 term 查询的模糊等价。它允许用户搜索词条与实际词条的拼写出现偏差，但是偏差的编辑距离不得超过2：
GET /test/_search
{
  "query": {
    "fuzzy": {
      "title": "手机"
    }
  }
}


#如果我们只想获取其中的部分字段，我们可以添加_source 的过滤 includes：来指定想要显示的字段 excludes：来指定不想要显示的字段
GET /test/_search
{
  "_source": [
    "title",
    "price"
  ],
  "query": {
    "term": {
      "price": 2699
    }
  }
}


GET /test/_search
{
  "_source": {
    "includes": [
      "title",
      "price"
    ]
  },
  "query": {
    "term": {
      "price": 2699
    }
  }
}

# filter 过滤 所有的查询都会影响到文档的评分及排名。如果我们需要在查询结果中进行过滤，并且不希望过滤条件影响评分，那么就不要把过滤条件作为查询条件来用。而是使用filter 方式：
GET /test/_search
{
  "query": {
    "bool": {
      "must": {
        "match": {
          "title": "小米手机"
        }
      },
      "filter": {
        "range": {
          "price": {
            "gt": 2000,
            "lt": 3800
          }
        }
      }
    }
  }
}

# 如果一次查询只有过滤，没有查询条件，不希望进行评分，我们可以使用constant_score 取代只有filter 语句的 bool 查询。在性能上是完全相同的，但对于提高查询简洁性和清晰度有很大帮助。
GET /test/_search
{
  "query": {
    "constant_score": {
      "filter": {
        "range": {
          "price": {
            "gt": 2000,
            "lt": 3000
          }
        }
      }
    }
  }
}

# sort 排序
GET /test/_search
{
  "query": {
    "match": {
      "title": "小米手机"
    }
  },
  "sort": [
    {
      "price": {
        "order": "desc"
      }
    }
  ]
}

# 多字段排序
GET /test/_search
{
  "query": {
    "bool": {
      "must": {
        "match": {
          "title": "小米手机"
        }
      },
      "filter": {
        "range": {
          "price": {
            "gt": 2000,
            "lt": 3000
          }
        }
      }
    }
  },
  "sort": [
    {
      "price": {
        "order": "desc"
      }
    },
    {
      "_score": {
        "order": "desc"
      }
    }
  ]
}

# 分页
GET /test/_search
{
  "query": {
    "match_all": {}
  },
  "sort": [
    {
      "price": {
        "order": "asc"
      }
    }
  ],
  "from": 3,
  "size": 3
}


#高亮   fields：这里声明title字段需要高亮
GET /test/_search
{
  "query": {
    "match": {
      "title": "手机"
    }
  },
  "highlight": {
    "pre_tags": "<em>",
    "post_tags": "</em>",
    "fields": {
      "title": {}
    }
  }
}


PUT /car
{
  "mappings": {
    "properties": {
      "color": {
        "type": "keyword"
      },
      "make": {
        "type": "keyword"
      }
    }
  }
}

# 批量添加
POST /car/_doc/_bulk
{ "index": {}}
{ "price" : 10000, "color" : "红", "make" : "本田", "sold" : "2020-10-28" }
{ "index": {}}
{ "price" : 20000, "color" : "红", "make" : "本田", "sold" : "2020-11-05" }
{ "index": {}}
{ "price" : 30000, "color" : "绿", "make" : "福特", "sold" : "2020-05-18" }
{ "index": {}}
{ "price" : 15000, "color" : "蓝", "make" : "丰田", "sold" : "2020-07-02" }
{ "index": {}}
{ "price" : 12000, "color" : "绿", "make" : "丰田", "sold" : "2020-08-19" }
{ "index": {}}
{ "price" : 20000, "color" : "红", "make" : "本田", "sold" : "2020-11-05" }
{ "index": {}}
{ "price" : 80000, "color" : "红", "make" : "宝马", "sold" : "2020-01-01" }
{ "index": {}}
{ "price" : 25000, "color" : "蓝", "make" : "福特", "sold" : "2020-02-12" }

#size： 查询条数，这里设置为0，因为我们不关心搜索到的数据，只关心聚合结果，提高效率aggs：声明这是一个聚合查询，是aggregations的缩写
# popular_colors：给这次聚合起一个名字，可任意指定。
# terms：聚合的类型，这里选择terms，是根据词条内容（这里是颜色）划分
# field：划分桶时依赖的字段
GET /car/_search
{
  "size": 0,
  "aggs": {
    "popular_colors": {
      "terms": {
        "field": "color"
      }
    }
  }
}


##求平均价格并且聚合数据升序
GET /car/_search
{
  "size": 0,
  "aggs": {
    "popular_colors": {
      "terms": {
        "field": "color",
        "order": [
          {
            "avg_price": "asc"
          },
          {
            "_key": "asc"
          }
        ]
      },
      "aggs": {
        "avg_price": {
          "avg": {
            "field": "price"
          }
        }
      }
    }
  }
}


#删除数据
DELETE /test/_doc/2

#查询索引下的全部数据
POST pms/_search


DELETE my_index


# 动态模板添加索引
PUT my_index
{
  "mappings": {
    "dynamic_templates": [
      {
        "strings_as_boolean": {
          "match_mapping_type":   "string",
          "match":"is*",
          "mapping": {
            "type": "boolean"
          }
        }
      },
      {
        "strings_as_long": {
          "match_mapping_type":   "string",
          "match":"long*",
          "mapping": {
            "type": "long"
          }
        }
      },
      {
        "strings_as_keywords": {
          "match_mapping_type":   "string",
          "match":"k*",
          "mapping": {
            "type": "keyword"
          }
        }
      },
      {
        "strings_as_text": {
          "match_mapping_type":   "string",
          "mapping": {
            "type": "text"
          }
        }
      }
    ]
  }
}

GET my_index


PUT my_index/_doc/1
{
  "firstName":"Ruan",
  "isVIP":"true"
}

#添加数据
PUT my_index/_doc/2
{
  "firstName":"Ruan",
  "isVIP":"true",
  "kName":"john"
  
}

PUT my_index/_doc/
{
  "firstName":"Ruan",
  "isVIP":"true",
  "kName":"john"
  
}

PUT my_index/_doc/2






GET /_analyze
{
"analyzer": "ik_max_word",
"text": "我是中国人"
}

GET /_analyze
{
"analyzer": "ik_smart",
"text": "我是中国人"
}


```
### 3、Elasticsearch的写入原理
```
es 写数据过程
客户端选择一个 node 发送请求过去，这个 node 就是 coordinating node（协调节点）。
coordinating node 对 document 进行路由，将请求转发给对应的 node（有 primary shard）。
实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node。
coordinating node 如果发现 primary node 和所有 replica node 都搞定之后，就返回响应结果给客户端。
```

```
es 读数据过程
可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询。

客户端发送请求到任意一个 node，成为 coordinate node。
coordinate node 对 doc id 进行哈希路由，将请求转发到对应的 node，此时会使用 round-robin随机轮询算法，在 primary shard 以及其所有 replica 中随机选择一个，让读请求负载均衡。
接收请求的 node 返回 document 给 coordinate node。
coordinate node 返回 document 给客户端。

es 读数据搜索过程
根据 java 关键词来搜索，将包含 java的 document 给搜索出来。es 就会给你返回：java真好玩儿啊，java好难学啊。

客户端发送请求到一个 coordinate node。
协调节点将搜索请求转发到所有的 shard 对应的 primary shard 或 replica shard，都可以。
query phase：每个 shard 将自己的搜索结果（其实就是一些 doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。
fetch phase：接着由协调节点根据 doc id 去各个节点上拉取实际的 document数据，最终返回给客户端。
```



#### 1:es写入原理

![elasticsearch写入原理](.\images\elasticsearch写入原理.png)

![elasticsearch写入原理1](.\images\elasticsearch写入原理1.png)


```
先写入内存 buffer，在 buffer 里的时候数据是搜索不到的；同时将数据写入 translog 日志文件。

如果 buffer 快满了，或者到一定时间，就会将内存 buffer 数据 refresh 到一个新的 segment file 中，但是此时数据不是直接进入 segment file 磁盘文件，而是先进入 os cache 。这个过程就是 refresh。

每隔 1 秒钟，es 将 buffer 中的数据写入一个新的 segment file，每秒钟会产生一个新的磁盘文件 segment file，这个 segment file 中就存储最近 1 秒内 buffer 中写入的数据。

但是如果 buffer 里面此时没有数据，那当然不会执行 refresh 操作，如果 buffer 里面有数据，默认 1 秒钟执行一次 refresh 操作，刷入一个新的 segment file 中。

操作系统里面，磁盘文件其实都有一个东西，叫做 os cache，即操作系统缓存，就是说数据写入磁盘文件之前，会先进入 os cache，先进入操作系统级别的一个内存缓存中去。只要 buffer中的数据被 refresh 操作刷入 os cache中，这个数据就可以被搜索到了。

为什么叫 es 是准实时的？ NRT，全称 near real-time。默认是每隔 1 秒 refresh 一次的，所以 es 是准实时的，因为写入的数据 1 秒之后才能被看到。可以通过 es 的 restful api 或者 java api，手动执行一次 refresh 操作，就是手动将 buffer 中的数据刷入 os cache中，让数据立马就可以被搜索到。只要数据被输入 os cache 中，buffer 就会被清空了，因为不需要保留 buffer 了，数据在 translog 里面已经持久化到磁盘去一份了。

重复上面的步骤，新的数据不断进入 buffer 和 translog，不断将 buffer 数据写入一个又一个新的 segment file 中去，每次 refresh 完 buffer 清空，translog 保留。随着这个过程推进，translog 会变得越来越大。当 translog 达到一定长度的时候，就会触发 commit 操作。

commit 操作发生第一步，就是将 buffer 中现有数据 refresh 到 os cache 中去，清空 buffer。然后，将一个 commit point写入磁盘文件，里面标识着这个 commit point 对应的所有 segment file，同时强行将 os cache 中目前所有的数据都 fsync 到磁盘文件中去。最后清空 现有 translog 日志文件，重启一个 translog，此时 commit 操作完成。

这个 commit 操作叫做 flush。默认 30 分钟自动执行一次 flush，但如果 translog 过大，也会触发 flush。flush 操作就对应着 commit 的全过程，我们可以通过 es api，手动执行 flush 操作，手动将 os cache 中的数据 fsync 强刷到磁盘上去。

translog 日志文件的作用是什么？你执行 commit 操作之前，数据要么是停留在 buffer 中，要么是停留在 os cache 中，无论是 buffer 还是 os cache 都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件 translog 中，一旦此时机器宕机，再次重启的时候，es 会自动读取 translog 日志文件中的数据，恢复到内存 buffer 和 os cache 中去。

translog 其实也是先写入 os cache 的，默认每隔 5 秒刷一次到磁盘中去，所以默认情况下，可能有 5 秒的数据会仅仅停留在 buffer 或者 translog 文件的 os cache 中，如果此时机器挂了，会丢失 5 秒钟的数据。但是这样性能比较好，最多丢 5 秒的数据。也可以将 translog 设置成每次写操作必须是直接 fsync 到磁盘，但是性能会差很多。

实际上你在这里，如果面试官没有问你 es 丢数据的问题，你可以在这里给面试官炫一把，你说，其实 es 第一是准实时的，数据写入 1 秒后可以搜索到；可能会丢失数据的。有 5 秒的数据，停留在 buffer、translog os cache、segment file os cache 中，而不在磁盘上，此时如果宕机，会导致 5 秒的数据丢失。

总结一下，数据先写入内存 buffer，然后每隔 1s，将数据 refresh 到 os cache，到了 os cache 数据就能被搜索到（所以我们才说 es 从写入到能被搜索到，中间有 1s 的延迟）。每隔 5s，将数据写入 translog 文件（这样如果机器宕机，内存数据全没，最多会有 5s 的数据丢失），translog 大到一定程度，或者默认每隔 30mins，会触发 commit 操作，将缓冲区的数据都 flush 到 segment file 磁盘文件中。
数据写入 segment file 之后，同时就建立好了倒排索引。
```
```
删除/更新数据底层原理
如果是删除操作，commit 的时候会生成一个 .del 文件，里面将某个 doc 标识为 deleted 状态，那么搜索的时候根据 .del 文件就知道这个 doc 是否被删除了。

如果是更新操作，就是将原来的 doc 标识为 deleted 状态，然后新写入一条数据。

buffer 每 refresh 一次，就会产生一个 segment file，所以默认情况下是 1 秒钟一个 segment file，这样下来 segment file 会越来越多，此时会定期执行 merge。每次 merge 的时候，会将多个 segment file 合并成一个，同时这里会将标识为 deleted 的 doc 给物理删除掉，然后将新的 segment file 写入磁盘，这里会写一个 commit point，标识所有新的 segment file，然后打开 segment file 供搜索使用，同时删除旧的 segment file。
```

### 3、读写性能调优

#### 	写入性能调优：

- 增加flush时间间隔，目的是减小数据写入磁盘的频率，减小磁盘IO

- 增加refresh_interval的参数值，目的是减少segment文件的创建，减少segment的merge次数，merge是发生在jvm中的，有可能导致full GC，增加refresh会降低搜索的实时性。

- 增加Buffer大小，本质也是减小refresh的时间间隔，因为导致segment文件创建的原因不仅有时间阈值，还有buffer空间大小，写满了也会创建。         默认最小值 48MB< 默认值 堆空间的10% < 默认最大无限制

- 大批量的数据写入尽量控制在低检索请求的时间段，大批量的写入请求越集中越好。

  - 第一是减小读写之间的资源抢占，读写分离
  - 第二，当检索请求数量很少的时候，可以减少甚至完全删除副本分片，关闭segment的自动创建以达到高效利用内存的目的，因为副本的存在会导致主从之间频繁的进行数据同步，大大增加服务器的资源占用。

- Lucene的数据的fsync是发生在OS cache的，要给OS cache预留足够的内从大小，详见JVM调优。

- 通用最小化算法，能用更小的字段类型就用更小的，keyword类型比int更快，

- ignore_above：字段保留的长度，越小越好

- 调整_source字段，通过include和exclude过滤

- store：开辟另一块存储空间，可以节省带宽

  ***\*注意：_\*******\*sourse\*******\*：\*******\*设置为false\*******\*，\*******\*则不存储元数据\*******\*，\*******\*可以节省磁盘\*******\*，\*******\*并且不影响搜索\*******\*。但是禁用_\*******\*source必须三思而后行\*******\*：\****

  \1. [update](https://www.elastic.co/guide/en/elasticsearch/reference/7.9/docs-update.html)，[update_by_query](https://www.elastic.co/guide/en/elasticsearch/reference/7.9/docs-update-by-query.html)和[reindex](https://www.elastic.co/guide/en/elasticsearch/reference/7.9/docs-reindex.html)不可用。

  \2. 高亮失效

  \3. reindex失效，原本可以修改的mapping部分参数将无法修改，并且无法升级索引

  \4. 无法查看元数据和聚合搜索

  影响索引的容灾能力

- 禁用_all字段：_all字段的包含所有字段分词后的Term，作用是可以在搜索时不指定特定字段，从所有字段中检索，ES 6.0之前需要手动关闭

- 关闭Norms字段：计算评分用的，如果你确定当前字段将来不需要计算评分，设置false可以节省大量的磁盘空间，有助于提升性能。常见的比如filter和agg字段，都可以设为关闭。

- 关闭index_options（谨慎使用，高端操作）：词设置用于在index time过程中哪些内容会被添加到倒排索引的文件中，例如TF，docCount、postion、offsets等，减少option的选项可以减少在创建索引时的CPU占用率，不过在实际场景中很难确定业务是否会用到这些信息，除非是在一开始就非常确定用不到，否则不建议删除

  ### 搜索速度调优

- 禁用swap

- 使用filter代替query

- 避免深度分页，避免单页数据过大，可以参考百度或者淘宝的做法。es提供两种解决方案scroll search和search after

- 注意关于index type的使用

- 避免使用稀疏数据

- 避免单索引业务重耦合

- 命名规范

- 冷热分离的架构设计

- fielddata：搜索时正排索引，doc_value为index time正排索引。

- enabled：是否创建倒排索引

- doc_values：正排索引，对于不需要聚合的字段，关闭正排索引可节省资源，提高查询速度

- 开启自适应副本选择（ARS），6.1版本支持，7.0默认开启，

### 4、ES的节点类型

- master：候选节点
- data：数据节点
- data_content：数据内容节点
- data_hot：热节点
- data_warm：索引不再定期更新，但仍可查询
- data_code：冷节点，只读索引
- Ingest：预处理节点，作用类似于Logstash中的Filter
- ml：机器学习节点
- remote_cluster_client：候选客户端节点
- transform：转换节点
- voting_only：仅投票节点

### 5、Mater选举过程

- #### 	设计思路：所有分布式系统都需要解决数据的一致性问题，处理这类问题一般采取两种策略：

  - #### 避免数据不一致情况的发生

  - #### 定义数据不一致后的处理策略

- #### 主从模式和无主模式

  - #### ES为什么使用主从模式？

    - 在相对稳定的对等网络中节，点的数量远小于单个节点可以维护的节点数，并且网络环境不必经常处理节点的加入和离开。

- #### ES的选举算法

  - Bully和Paxos

- #### 脑裂是什么以及如何避免

  

### 6、Elasticsearch调优

- #### 通用法则

  - 通用最小化算法：对于搜索引擎级的大数据检索，每个bit尤为珍贵。
  - 业务分离：聚合和搜索分离

- #### 数据结构 学员案例

- #### 硬件优化

  ​		es的默认配置是一个非常合理的默认配置，绝大多数情况下是不需要修改的，如果不理解某项配置的含义，没有经过验证就贸然修改默认配置，可能造成严重的后果。比如max_result_window这个设置，默认值是1W，这个设置是分页数据每页最大返回的数据量，冒然修改为较大值会导致OOM。ES没有银弹，不可能通过修改某个配置从而大幅提升ES的性能，通常出厂配置里大部分设置已经是最优配置，只有少数和具体的业务相关的设置，事先无法给出最好的默认配置，这些可能是需要我们手动去设置的。关于配置文件，如果你做不到彻底明白配置的含义，不要随意修改。

  ​		jvm heap分配：7.6版本默认1GB，这个值太小，很容易导致OOM。Jvm heap大小不要超过物理内存的50%，最大也不要超过32GB（compressed oop），它可用于其内部缓存的内存就越多，但可供操作系统用于文件系统缓存的内存就越少，heap过大会导致GC时间过长

  - 节点：

    根据业务量不同，内存的需求也不同，一般生产建议不要少于16G。ES是比较依赖内存的，并且对内存的消耗也很大，内存对ES的重要性甚至是高于CPU的，所以即使是数据量不大的业务，为了保证服务的稳定性，在满足业务需求的前提下，我们仍需考虑留有不少于20%的冗余性能。一般来说，按照百万级、千万级、亿级数据的索引，我们为每个节点分配的内存为16G/32G/64G就足够了，太大的内存，性价比就不是那么高了。

  -  内存：

    根据业务量不同，内存的需求也不同，一般生产建议不要少于16G。ES是比较依赖内存的，并且对内存的消耗也很大，内存对ES的重要性甚至是高于CPU的，所以即使是数据量不大的业务，为了保证服务的稳定性，在满足业务需求的前提下，我们仍需考虑留有不少于20%的冗余性能。一般来说，按照百万级、千万级、亿级数据的索引，我们为每个节点分配的内存为16G/32G/64G就足够了，太大的内存，性价比就不是那么高了。

  -  磁盘：

    对于ES来说，磁盘可能是最重要的了，因为数据都是存储在磁盘上的，当然这里说的磁盘指的是磁盘的性能。磁盘性能往往是硬件性能的瓶颈，木桶效应中的最短板。ES应用可能要面临不间断的大量的数据读取和写入。生产环境可以考虑把节点冷热分离，“热节点”使用SSD做存储，可以大幅提高系统性能；冷数据存储在机械硬盘中，降低成本。另外，关于磁盘阵列，可以使用raid 0。

  - CPU：

    CPU对计算机而言可谓是最重要的硬件，但对于ES来说，可能不是他最依赖的配置，因为提升CPU配置可能不会像提升磁盘或者内存配置带来的性能收益更直接、显著。当然也不是说CPU的性能就不重要，只不过是说，在硬件成本预算一定的前提下，应该把更多的预算花在磁盘以及内存上面。通常来说单节点cpu 4核起步，不同角色的节点对CPU的要求也不同。服务器的CPU不需要太高的单核性能，更多的核心数和线程数意味着更高的并发处理能力。现在PC的配置8核都已经普及了，更不用说服务器了。

  -  网络： 

    ES是天生自带分布式属性的，并且ES的分布式系统是基于对等网络的，节点与节点之间的通信十分的频繁，延迟对于ES的用户体验是致命的，所以对于ES来说，低延迟的网络是非常有必要的。因此，使用扩地域的多个数据中心的方案是非常不可取的，ES可以容忍集群夸多个机房，可以有多个内网环境，支持跨AZ部署，但是不能接受多个机房跨地域构建集群，一旦发生了网络故障，集群可能直接GG，即使能够保证服务正常运行，维护这样（跨地域单个集群）的集群带来的额外成本可能远小于它带来的额外收益。

  - 集群规划：没有最好的配置，只有最合适的配置。

  - 在集群搭建之前，首先你要搞清楚，你ES cluster的使用目的是什么？主要应用于哪些场景，比如是用来存储事务日志，或者是站内搜索，或者是用于数据的聚合分析。针对不同的应用场景，应该指定不同的优化方案。

  - 集群需要多少种配置（内存型/IO型/运算型），每种配置需要多少数量，通常需要和产品运营和运维测试商定，是业务量和服务器的承载能力而定，并留有一定的余量。

  -  一个合理的ES集群配置应不少于5台服务器，避免脑裂时无法选举出新的Master节点的情况，另外可能还需要一些其他的单独的节点，比如ELK系统中的Kibana、Logstash等。

- #### 架构优化:

  - #### 合理的分配角色和每个节点的配置，在部署集群的时候，应该根据多方面的情况去评估集群需要多大规模去支撑业务。这个是需要根据在你当前的硬件环境下测试数据的写入和搜索性能，然后根据你目前的业务参数来动态评估的，比如：

    - 业务数据的总量、每天的增量
    - 查询的并发以及QPS
    - 峰值的请求量

  - #### 节点并非越多越好，会增加主节点的压力

  - #### 分片并非越多越好，从deep pageing 的角度来说，分片越多，JVM开销越大，负载均衡（协调）节点的转发压力也越大，查询速度也越慢。单个分片也并非越大越好，一般来说单个分片大小控制在30-50GB。

  - 

- #### Mpping优化：

  - #### 优化字段的类型，关闭对业务无用的字段

  - #### 尽量不要使用dynamic mapping分片大小

- #### Developer调优：修炼内功，提升修养

### 7、索引备份还原
```

为上述索引创建一个snapshot
PUT /_snapshot/my_fs_backup/snapshot_test_1?wait_for_completion=true
{undefined
  "indices": "test",
  "ignore_unavailable": true,
  "include_global_state": false
}

4.删除上述索引
DELETE test
5.恢复上述索引
POST /_snapshot/my_fs_backup/snapshot_test_1/_restore
{undefined
  "indices": "test",
  "ignore_unavailable": true,
  "include_global_state": true
}
```


### 8、数据同步方案

- #### 数据一致性问题

- #### 基于Canal+binlog同步MySql

- #### 基于packetbeat监听9200端口

### 9、搜索引擎和ES（搜索引擎的原理、ES的认识或理解）（课时1）

- #### 概念：大数据检索（区分搜索）、大数据分析、大数据存储

- #### 性能：PB级数据秒查（NRT Near Real Time）

  - 高效的压缩算法
  - 快速的编码和解码算法
  - 合理的数据结构
  - 通用最小化算法

- #### 场景：搜索引擎、垂直搜索、BI、GIthub、ELKB

- #### 大厂：JD、百度、阿里、腾讯、滴滴、字节、美团、Github、马士兵教育（如果记不住，就把你能想到的大厂有几个说几个）。

## 总结

1. ### 简历要简洁美观、突出重点，HR是你的第一关。

2. #### 适当包装≠欺骗

   1. 工作年限
   2. 技能水平
   3. 项目经验

3. ### 自信、大胆、勇敢！

   1. 面试当成是聊天，不要当做考试。
   2. 要薪资不要怂，给自己加价保底30%，切忌自降身价。举一个真实的例子，8-10-12
   3. 有问题答不上来也不要紧张，有的同学面试一有问题答不上来就否定自己，甚至脸涨的通红，想找个地缝钻进去，觉得自己好丢人。大可不必这么想，你不是彭于晏也不是吴彦祖，你来面试没人认识你，面试的再不好，结束之后你离开公司用不了十分钟就没人会再记得你。我举个典型的例子，有一次我们敬爱的马老师有次亲自作为面试官面试本公司的开发工程师，面试之后不到一个小时我忘了是因为想录用还是其他别的原因要问刚面试的那个同学叫啥名字了，结果就算见过他面的人也没人记得。你想，面试官一天要面试的人可能有好多，每个月要面试几十上百人，他怎么可能把你记得那么清楚。所以不管你面试的过程中出现任何问题，完全没必要胆怯，此处不留爷自有留爷处，这家不行，咱们Next one，公司千千万，是金子总会发光，不是金子总有眼瞎的。

4. ### 特别想去的公司

   如果有特别想去的公司，很多同学就因为他别想去，而过于担心如果进不去怎么办，反而自乱阵脚。

   首先如果有目标特别明确的，特别想进的公司，首先根据提供的JD，做足准备，可以先去其他公司找找多试试，如果成了，那就是给自己多留了几个后手，最后再去想去的公司，第一是短时间内的多次面试已经给自己发现了很多问题，也为自己补充了很多面试经验。第二是自己在自己手里已经有offer的时候，再去面试目标公司，那心里就会更加有底，就算进不去也不至于没有公司去，当然后手准备的越多越好，手里offer越多，面试就越不慌，心态就越平和，越容易正常发挥不会被紧张左右情绪

5. ### 如何面对不会的问题

6. ### 有不懂的很正常，面试官问的，也许只是他擅长的。
   1. 不正面回答，这时聊一些相关性的知识点，劲儿把话题引导到自己会的知识上去，但是不要天马行空，说话完全不着边际
   2. 学会如何绕开话题，把话题带到自己会的知识上来。
   3. 遇到真的完全没遇到过的问题，先别着急说不知道，面试官有时候只是想听听你是如何思考和解决问题的，不一定要你现场就得解决问题，如果确实完全无从下手，大大方方的承认，任何人不可能面面俱到，有没接触过的东西很正常，但是说话要注意方式，不要直接说这个我不会。当然这是在前面几点没办法解决的前提下，如果问什么都是无从下手，那还是得从提升自身技能着手了。

7. ### 注意自己的形象和言语谈吐

   你和面试官是初次见面，言语要稳重些，不要过于轻浮，能不开玩笑就不要开玩笑。面试面的不仅仅是你的技术实力，还有你的领导力、人品、和颜值（我们尽量不要以貌取人，但是不排除别人会以貌取人），吗，因此发型要干净得体，不要穿的过于正式或随便，不要发型搞的太夸张，比如男生扎小辫、披肩发，就算你技术非常牛逼，技术面试官非常青睐你，你有可能栽在HR手里。我这里没有对弄这些发型的同志们有成见的意思，就是一个提醒，如果是真的喜欢，可以入职以后，想怎么搞怎么搞。我说一下我的亲身经历某友，某捷通。

8. ### 真正的智者，知进退，懂隐忍。

   面试是一个展示自身技能的过程，但是对于目前岗位够用就行，不要过于发挥，着急的表现自己的技术，你比面试官强的那部分能力是要留着给老板或者更高的领导看的，可以等入职之后再去展示。凡事留三分余地，做人留一面，来日好相见。你现在生杀大权在面试官手里，如果你表现的压他一头，好像要多她饭碗似的，他岂能留你？不可能每个面试官都是胸襟宽广的，害人之心不可有，防人之心不可无。想想曹冲怎么死的。莫让英雄无用武之地，凉了你的赤胆雄心，负了你满腔抱负，惜了一身的才华，英雄无用武之地。

9. ### 夯实基础，修炼内功，把功夫用在平时。

   是金子总会发光，我们不能总是指望遇到瞎子。面试就像相亲，即是老板选你，也是你选老板。都是双发对彼此有个初步的认识。试用期就是在谈恋爱，都是在彼此发现问题以及解决问题的过程，谈得来就谈，谈不来就散，能不能转正，基本还是要看你自己。但是如果谈不来，损失更大的是你自己，因为公司可以在招一个，而你的经历就会被写在履历里，想改也改不掉。

10. ### 切勿好高骛远，好大喜功。

11. ### 最好有大厂履历，大厂经历是一张不错的名片。

12. ### 勿频繁跳槽。

13. ### 如何看待加班问题

    如果面试官问到，你如何看待加班问题，千万别把话说的过于绝对，比如有加班费就行，或者直说拒绝加班，说法律上说的怎样怎样，首先如果你还想在一家公司待下去。国家在面对一些问题的态度上仍尽量采取和平手段，你觉得你会比国家更加明智吗？凡是寻求稳妥。

    当然我也不是说让你无底线的接受加班，说我可以随时加班，加班到随时，加班使我快乐，我爱加班。如果面试官问你何为高强度，以自身感觉是否会熬坏身体为理由，别回答的太绝对，比比如回答 996就是高强度或者一天超过X小时就是高强度，记住一点，任何问题，除了期望薪资，都别回答那么绝对，别给面试官一种过了这条线就不行那种感觉，相亲的时候，如果你想找个肤白貌美的，170的。100斤的，月入2W的，本科学历的，独生子的，假如身高165矮了5厘米，或者体重105重了五斤，但是美的不可方物，你就坚决不要么？所以不要给面试官这种感觉，低于170的坚决不要，就是不要给他一个明确的界限，只要不在某一方面过于偏科就行），但是接受高强度的紧急加班。那些说只要工作效率低的人才会加班，效率高的都会在8小时工时之内完成任务的人话说的可能也有些片面了。首先除了部分国企或外企之外互联网公司多多少少都是存在加班现象的，这是你没得选择的，合理的加班也是可以理解的，公司养一个员工确实成本也挺大的，要为你缴纳高额的社保还有企业所得税等，作为决策者他不得不为成本去考虑，为人者知谦卑、懂感恩、有胸怀。说心里话，我们之中相当一部分人得到其实是大于其为公司带来的价值的，所以其实有时候不仅人与人之间要学会换位思考，人与企业之间也要学会换位思考，你事事为公司着想，老板不会看不到的。所以面对加班，正确的答案应该是，对于平日里的一定量加班，我们也应与理解，不要老是死磕那一二十块钱的加班费，不仅显得你格局小，而且有那个时间，不如去提升一下自己的硬实力，提高自己的价值。其次面对如项目上线、突发状况的加班，即便是可能是需要通宵，比较辛苦，也是可以接受的，不要除了抱怨还是抱怨。

    最后就是面对高强度的日常加班，我说过，员工和企业要学会换位思考，既要有为公司奉献的觉悟，也不能被公司过分压榨。因为我们作为员工如果事实为公司考虑，比如牺牲了自己爱人、子女的时间换来的是无休止的压榨，如007（一天12小时，一周工作七天成为了日常），那可能最终熬坏了身体还不落好，这种情况不用想，绝不接受，身体是革命的本钱。赚再多的钱，也需要得有命花。

    **总结一下加班的正确答复**：原则上是拒绝无休止的高强度日常加班（何为被问高强度我刚才已经教你怎么说了），但是如果公司有突发状况如项目上线，需要高强度加班是完全可以理解的，这也是我觉得一个合格的开发应该有的觉悟吧（这里注意说话的语气和言辞以及方式）。

    PS：不针对面试，就说说咱们自己应该如何看待加班。不要把加班看成一种吃亏，对于没对象的同学，仔细想想，你下班回去可能无非就是处理一些杂事儿、或者玩游戏、追剧。如果你是想追求更高目标的，可能公司也许有更好的学习环境和氛围，即便你完成了领导要求的任务，不如多思考一下哪些东西可以做的更好或者哪些东西是将来有可能需要的，即便现在可能用不到，你也可以借此来尝试一些自己想要学习的技术，比如之前的方案采用的是基于MySql的方案，思考一下是否采用ES效果更好，有了想法就是学，就去做。一般来说公司也都会愿意为你提供一些资源，比如你的测试机应该完全够你部署一些你学习过程中需要的服务。就算没有也可以想方设法的搞一些环境，比如阿里云有提供学习用的低配ECS，每年只需要100块钱。是在不行在你的PC上也可以搞，搞几台虚拟机搭个集群自己随便搞有啥不好，只要你想学，什么都拦不住你。等你的实验项目落实了，完全可以做个测试拿出个方案出来，比如你测试了使用MySql和ES两种的搜索方案的性能对比出来，如果有理有据，并且愿意分享成果，相信你的领导也愿意支持你，即便这东西现在用不上，但是如果哪天突然领导提出了这样的需求，你高速领导，这事儿我已经做好了，你看。你觉得公司会不喜欢这样处处为公司着想的员工么。你不但学到了东西，而且还把握住了机会，如果将来有晋升的名额，你你也许就有机会。但是要记住一点就是有任何功劳都要记得与别人分享，尤其是你的直系领导，这是在某领导的英明决策和指挥以及全力支持下，有你去落实的。不然就算你的能力是货真价实的，可能也会被埋没，其实看起来是你的功劳被别人占了便宜，其实是你占便宜了。因为你只有把利益和别人扯上关系，别人才会主动帮你推这件事儿。并且你懂得分享功劳，领导如果升迁，难道它的位置第一个想举荐的不肯定就是你吗？这其实也是良性循环，你想得到的得到了，你为公司带来了价值，公司给你了更大的施展空间。即便事情没有这么理想，你在公司没有遇到这样的机会，你至少也是学到了东西，你做的东西在以后的面试中、工作中可能都用得到。换个角度，你会发现一大片天空。





